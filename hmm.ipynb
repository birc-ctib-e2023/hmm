{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A hidden Markov model gene-finder\n",
    "\n",
    "In the exercise below, you will implement and experiment with an example of how to apply a HMM for identifying coding regions(genes) in genetic material. We consider only procaryotes, which have a particular simple gene format. A gene is a sequence of triplets, codons, that encode proteins. We saw this in the first project. Now, we assume that we have a genomic sequence, and our goal is to recognise which part of the genome encodes genes, and which do not.\n",
    "\n",
    "Genes can be found on both strands of a genome, so as we scan along the genome sequence, we might encounter them in the direction we are scanning, or we might encounter them in the reverse order, seeing them backwards, so to speak. In either case, we recon that gene coding sequences likely have a different nucleotide composition, and we will exploit this in our model.\n",
    "\n",
    "We build a hidden Markov model, where the hidden states are:\n",
    "\n",
    "- Non-coding: we are not in a coding sequence\n",
    "- Coding: We are inside a gene that is coded in the direction we are reading\n",
    "- Reverse coding: We are inside a gene that is encoded on the other strand than then one we are scanning\n",
    "\n",
    "We will use two different models. A 3-state HMM that encodes only the three states we just listed, and a 7-state HMM that adds a little more structure. It models that genes come as codons, so when we are inside a gene, we should always a number of nucleotides divisible by three, and if the nucleotide composition is different for different codon positions, it can model that as well.\n",
    "\n",
    "We can draw the two models like this:\n",
    "\n",
    "![Gene-finder models](figures/gene-finder-models.png)\n",
    "\n",
    "\n",
    "Both have coding states (C), non-coding states (N), and reverse-coding states (R), but the second has three of each of C and R. The numbers in square brackets in the states are just that, numbers. Specifically numbers from zero up to the number of states minus one. Representing states like that is convinient if we are to use states to index into vectors and matrices.\n",
    "\n",
    "There is another purpose to this project, beyond learning how to implement and apply hidden Markov models. We will do the project in a so-called [Jupyter Notebook](https://jupyter.org). Jupyter is one of many ways of combining documentation and code, a technique known as literate programming although it is rarely used in programming but quite frequently in data science. The text you are reading now is, in fact, written in a Jupyter Notebook that contains both the project description and the template code you need to get started. The file is named `hmm.ipynb`, and you should edit that file to fill out the missing details.\n",
    "\n",
    "**WARNING:** DO NOT EDIT `README.md`. When you commit to GitHub, `README.md` will be overwritten by a file extracted from `hmm.ipynb`. The only file you should edit in this project is `hmm.ipynb` (or any additional files you create for testing the code you write in `hmm.ipynb`).\n",
    "\n",
    "You can edit Jupyter Notebooks in several different ways. If you follow the link above to [jupyter.org](https://jupyter.org) you can get a browser interface. If you are using VSCode as your editor, you can install an extension and edit Jupyter files natively. (That is what I am doing). Your first exercise is to figure out how to edit `hmm.ipynb`. When you have managed that, proceed to the next section.\n",
    "\n",
    "Whenever you commit the notebook to GitHub it is evaluated from scratch, and the result becomes the new README.md. If you are evaluating cells out of order, your state might be different from one where you evaluate the notebook from the beginning, so be careful to check that the clean evaluation is correct.\n",
    "\n",
    "## Training data\n",
    "\n",
    "For this project, we have two bacterial genomes that someone has painstakingly annotated with genes (and I have then fracked up the good work to make the data look the way our models assume it will rather than the mess that God created).\n",
    "\n",
    "The two genomes, found in `data/genome1.fa` and `data/genome2.fa`, are stored in [FASTA files](https://en.wikipedia.org/wiki/FASTA_format), and I have provided a function you can used to load them. (It is not entirely general, but it suffices for parsing the FASTA files you need for this project).\n",
    "\n",
    "The function is in a module in `src` and we can import it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules from src directory\n",
    "import sys\n",
    "sys.path.insert(0, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the function for reading a fasta file\n",
    "from fasta import read_fasta_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function in hand, we can try to load one of the genomes and see what is in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['genome', 'annotation'])\n",
      "dict_keys(['genome', 'annotation'])\n"
     ]
    }
   ],
   "source": [
    "genome1 = read_fasta_file('data/genome1.fa')\n",
    "genome2 = read_fasta_file('data/genome2.fa')\n",
    "print(genome1.keys())\n",
    "print(genome2.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like you get a dictionary with two keys, `genome` and `annotation`, and I will bet you good money that the former is the genomic sequence and the second the annotation. Let's have a look at them (but don't print all of them, as they are quite long):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1852441 1852441\n",
      "TTGTTGATATTCTGTTTTTTCTTTTTTAGTTTTCCACATGAAAAATAGTTGAAAACAATA\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n"
     ]
    }
   ],
   "source": [
    "print(len(genome1['genome']), len(genome1['annotation']))\n",
    "print(genome1['genome'][:60])\n",
    "print(genome1['annotation'][:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genomic sequence is a sequence over the letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A', 'C', 'G', 'T'}\n"
     ]
    }
   ],
   "source": [
    "print(set(genome1['genome']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while the annotation is a sequence over the letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N', 'R', 'C'}\n"
     ]
    }
   ],
   "source": [
    "print(set(genome1['annotation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that should be interpreted as non-coding, reverse-coding, and coding.\n",
    "\n",
    "If we are to analyse such a genome using a hidden Markov model, we must be able to use both the observable letters (the genomic sequence) and the hidden states (the annotation) as indices into matrices or vectors.\n",
    "\n",
    "For the three-states model, the $\\pi$ vector should have length three, and we should be able to index into it with hidden states, $\\pi[z]$; we should be able to index into the transition matrix $T$, a $3\\times 3$ matrix, with two hidden states $T[s,t]$, and we should be able to index into the emission matrix, a $3\\times 4$ matrix, with a hidden state $z$ and an observed nucleotide, $x$, $E[z,x]$.\n",
    "\n",
    "We could use dictionaries for this indexing, but it is much more convinient to represent vectors as vectors and matrices as matrices (we will see how below), and that requires that we use integers as indices. We need to map the two strings into lists of integers, in some way such that for the genomic sequence the integers are 0, 1, 2, or 3, and such that the annotation maps to integers 0, 1, or 3.\n",
    "\n",
    "I'll show you have to map the genomic sequence, and then you should write a function for mapping the annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observed_states(x: str) -> list[int]:\n",
    "    \"\"\"\n",
    "    Maps a DNA sequence to HMM emissions.\n",
    "    \n",
    "    >>> observed_states('ACAGTTC')\n",
    "    [0, 1, 0, 2, 3, 3, 1]\n",
    "    \"\"\"\n",
    "    map = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    return [map[a] for a in x]\n",
    "\n",
    "def rev_observed_states(obs: list[int]) -> str:\n",
    "    \"\"\"\n",
    "    Reverses the observable states mapping.\n",
    "    \n",
    "    In this notebook, we only use this for testing, but you can use it as\n",
    "    inspiration to write similar functions for the hidden states where you\n",
    "    do want to be able to reverse when you do decoding.\n",
    "        \n",
    "    >>> rev_observed_states([0, 1, 0, 2, 3, 3, 1])\n",
    "    'ACAGTTC'\n",
    "    \"\"\"\n",
    "    return ''.join('ACGT'[x] for x in obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped genome: [3, 3, 2, 3, 3, 2, 0, 3, 0, 3]\n",
      "TTGTTGATAT TTGTTGATAT\n"
     ]
    }
   ],
   "source": [
    "x = genome1['genome'][:10] # A shorter string to play with\n",
    "y = observed_states(x)\n",
    "print('mapped genome:', y)\n",
    "print(x, rev_observed_states(y))\n",
    "assert x == rev_observed_states(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: You need to implement the corresponding function for annotations\n",
    "# In the figure above, the states map as C -> 0, N -> 1 and R -> 2 but\n",
    "# you do not need to use that; but you do need to be consistent everywhere\n",
    "def hidden_states(x: str) -> list[int]:\n",
    "    \"\"\"\n",
    "    Map a genome annotation to hidden states (index 0, 1, or 2).\n",
    "    \n",
    "    >>> hidden_states('NNCCCCCCNNRRRRRRN')\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1]\n",
    "    \"\"\"\n",
    "    map = {'C': 0, 'N': 1, 'R': 2}\n",
    "    return [map[a] for a in x]\n",
    "\n",
    "def rev_hidden_states(hid: list[int]) -> str:\n",
    "    \"\"\"\n",
    "    Reverse the map of hidden states.\n",
    "    \n",
    "    This function should also be useful if you wish to convert a decoding\n",
    "    to the annotation format at some point in the future.\n",
    "    \n",
    "    >>> rev_hidden_states([1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1])\n",
    "    'NNCCCCCCNNRRRRRRN'\n",
    "    \"\"\"\n",
    "    return ''.join(\"CNR\"[h] for h in hid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped annotation: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NNNNNNNNNNNCCCCCCCCCCCCCCCCCCC NNNNNNNNNNNCCCCCCCCCCCCCCCCCCC\n"
     ]
    }
   ],
   "source": [
    "x = genome1['annotation'][220:250] # A shorter string to play with\n",
    "y = hidden_states(x)\n",
    "print('mapped annotation:', y)\n",
    "print(x, rev_hidden_states(y))\n",
    "assert x == rev_hidden_states(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem for the seven-state HMM, though. Our annotations have three states, `C`, `N`, and `R`, but the `C` and `R` annotations map to three separate states each in the seven-state model!\n",
    "\n",
    "It's not that it is a complete mystery which hidden states the different `C` or `R` annotations should map to. The coding regions come in triplets, so if we split a stretch of `C` positions into triplets\n",
    "\n",
    "```\n",
    "    ...NNCCCCCCCCCCCCCCCNN...\n",
    "=>  ...NN[CCC][CCC][CCC][CCC][CCC]NN...\n",
    "```\n",
    "\n",
    "they should obviously be mapped to repeats of `[0,1,2]` (according to the figure above), so this annotation should be interpreted as\n",
    "\n",
    "```\n",
    "    ...NN[CCC][CCC][CCC][CCC][CCC]NN...\n",
    "=>  ...33[012][012][012][012][012]33...\n",
    "```\n",
    "\n",
    "Likewise for stretches of `R` annotations.\n",
    "\n",
    "There are many fine ways to achieve this. A simple one is to look at the annotation and hidden state in the previous position and set the hidden state at the current position based on that.\n",
    "\n",
    "```python\n",
    " if ann[i] == 'C' and ann[i-1] != 'C':\n",
    "     hid[i] = 0\n",
    " if ann[i] == 'C' and ann[i-1] == 'C':\n",
    "     hid[i] = (hid[i-1] + 1) % 3\n",
    "```\n",
    "\n",
    "I don't really care how you do it, but I want it done. Write me a function that extracts the hidden states from a seven-state model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: You need to implement the corresponding function for annotations\n",
    "# In the figure above, the states map as C -> 0/1/2, N -> 3 and R -> 4/5/6 but\n",
    "# you do not need to use that; but you do need to be consistent everywhere\n",
    "def hidden_states7(x: str) -> list[int]:\n",
    "    \"\"\"\n",
    "    Map a genome annotation to hidden states.\n",
    "    \n",
    "    >>> hidden_states7('NNCCCCCCNNRRRRRRN')\n",
    "    [3, 3, 0, 1, 2, 0, 1, 2, 3, 3, 4, 5, 6, 4, 5, 6, 3]\n",
    "    \"\"\"\n",
    "    ann = [-1] * len(x)\n",
    "    for i, a in enumerate(x):\n",
    "        match a:\n",
    "            case 'N': ann[i] = 3\n",
    "            case 'C' if x[i - 1] != 'C':\n",
    "                ann[i] = 0\n",
    "            case 'C' if x[i - 1] == 'C':\n",
    "                ann[i] = (ann[i - 1] + 1) % 3\n",
    "            case 'R' if x[i - 1] != 'R':\n",
    "                ann[i] = 4\n",
    "            case 'R' if x[i - 1] == 'R':\n",
    "                ann[i] = (ann[i - 1] -4 + 1) % 3 + 4\n",
    "    return ann\n",
    "\n",
    "def rev_hidden_states7(hid: list[int]) -> str:\n",
    "    \"\"\"\n",
    "    Reverse the map of hidden states.\n",
    "    \n",
    "    This function should also be useful if you wish to convert a decoding\n",
    "    to the annotation format at some point in the future.\n",
    "    \n",
    "    >>> rev_hidden_states7([3, 3, 0, 1, 2, 0, 1, 2, 3, 3, 4, 5, 6, 4, 5, 6, 3])\n",
    "    'NNCCCCCCNNRRRRRRN'\n",
    "    \"\"\"\n",
    "    return ''.join(\"CCCNRRR\"[h] for h in hid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped annotation: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4]\n",
      "NNNNNNNNNNNNRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRR NNNNNNNNNNNNRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRR\n"
     ]
    }
   ],
   "source": [
    "x = genome1['annotation'][45110:45210]  # A shorter string to play with\n",
    "y = hidden_states7(x)\n",
    "print('mapped annotation:', y)\n",
    "print(x, rev_hidden_states7(y))\n",
    "assert x == rev_hidden_states7(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing likelihoods\n",
    "\n",
    "Now that we have transformed our input sequences into integer lists, we should be able to use these with a hidden Markov model. Let's make some (arbitrary) HMM parameters--`pi`, `T` and `E`--to see how.\n",
    "\n",
    "We will use the module `numpy` for this. It is a powerful library for linear algebra, but don't worry, we will just use it to make one- and two-dimensional tables that we index into efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pi = np.array([0, 1, 0]) # always start in N (== 1)\n",
    "T = np.array([\n",
    "    [0.8, 0.2, 0.0],  # Transitions out of C\n",
    "    [0.1, 0.8, 0.1],  # Transitions out of N\n",
    "    [0.0, 0.2, 0.8],  # Transitions out of R\n",
    "])\n",
    "E = np.array([\n",
    "    [0.3, 0.2, 0.1, 0.4],  # Emissions from C\n",
    "    [0.5, 0.1, 0.2, 0.2],  # Emissions from N\n",
    "    [0.2, 0.2, 0.3, 0.3],  # Emissions from R\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters here are not chosen to fit the model (which should be obvious from how regular the numbers look), but they are valid parameters in the sense that the initial transitions sum to one, that the out transitions sum to one for each state, and that the emissions sum to one for each state as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "assert_almost_equal(sum(pi), 1) # use \"almost equal\" on floats; never ==\n",
    "for s in [0, 1, 2]:\n",
    "    assert_almost_equal(sum(T[s,:]), 1)\n",
    "for s in [0, 1, 2]:\n",
    "    assert_almost_equal(sum(E[s, :]), 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As represented here, we have the three parameters floating around independently. There isn't anything wrong with that as such, but there are occations where you want to make sure that the parameters you have fitted for a model do not get mixed up with parameters from elsewhere, and it is easier to keep one object under control than three. The code below lets you wrap up the three parameters we use as a single object that we can pass around functions.\n",
    "\n",
    "You don't need to know how it works (although it isn't that complicated), as long as you know that you can call the function `hmm_params(pi,T,E)` to wrap the three parameters, and from the wrapped object, `theta`, you can get the parameters back, including a number `K` that is the number of hidden states.\n",
    "\n",
    "```python\n",
    "K, pi, T, E = theta\n",
    "```\n",
    "\n",
    "The number `K` is useful in some of the algorithms, and although you can always get it from the other three, it is more convinient to have it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.typing import ArrayLike\n",
    "from typing import NamedTuple\n",
    "\n",
    "HMMParam = NamedTuple('HMMParam', [\n",
    "    ('K', int),          # Number of hidden states\n",
    "    ('pi', ArrayLike),\n",
    "    ('T', ArrayLike),\n",
    "    ('E', ArrayLike)\n",
    "])\n",
    "\n",
    "def hmm_params(pi: ArrayLike, T: ArrayLike, E: ArrayLike) -> HMMParam:\n",
    "    \"\"\"Wraps HMM parameters in a tuple so we can pass them to functions\n",
    "    as a unit.\"\"\"\n",
    "    # Consistency check.\n",
    "    assert len(pi.shape) == 1  # must be one dimensional\n",
    "    assert len(T.shape) == 2   # must be two dimensional\n",
    "    assert len(E.shape) == 2   # must be two dimensional\n",
    "\n",
    "    # Get the number of states from pi and check that\n",
    "    # it matches with the expected dimensions in T and E.\n",
    "    K = len(pi)\n",
    "    assert T.shape == (K, K)\n",
    "    assert E.shape[0] == K\n",
    "    \n",
    "    # Consistency check done, we accept and wrap the parameters\n",
    "    return HMMParam(K, pi, T, E)\n",
    "\n",
    "theta = hmm_params(pi, T, E) # combining parameters from above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we can wrap up our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMMData = NamedTuple('HMMData', [\n",
    "    ('k', int),\n",
    "    ('x', list[int]),\n",
    "    ('z', list[int])\n",
    "])\n",
    "\n",
    "def hmm_data(k: int, x: str, z: str) -> HMMData:\n",
    "    \"\"\"\n",
    "    Wrap a genomic sequence and an annotation as an HMMData object.\n",
    "    \n",
    "    The parameter k determines if we use the three or seven state HMM.\n",
    "    \"\"\"\n",
    "    assert len(x) == len(z)\n",
    "    match k:\n",
    "        case 3:\n",
    "            return HMMData(k, observed_states(x), hidden_states(z))\n",
    "        case 7:\n",
    "            return HMMData(k, observed_states(x), hidden_states7(z))\n",
    "        case _:\n",
    "            assert False, \"We only have 3 and 7 state models\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just wrap up all our data once and for all, so we have it ready to go later\n",
    "data1_3 = hmm_data(3, genome1['genome'], genome1['annotation'])\n",
    "data1_7 = hmm_data(7, genome1['genome'], genome1['annotation'])\n",
    "data2_3 = hmm_data(3, genome2['genome'], genome2['annotation'])\n",
    "data2_7 = hmm_data(7, genome2['genome'], genome2['annotation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that we go from state $s$ to state $t$ is $T[s,t]$, so with our mapped sequences, let's call them `obs` for observed and `hid` for hidden, the probability of the transition at position `i` should be `T[hid[i],hid[i+1]]`. The probabiity of emitting what we have at position is `E[hid[i],obs[i]]`, and the probability of starting in the first state it `pi[hid[0]]`.\n",
    "\n",
    "Use these observations to implement a function that computes the likelihood of a genomic sequence and an annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lik(data: HMMData, theta: HMMParam) -> float:\n",
    "    \"\"\"\n",
    "    Compute the likelihood of the data (obs,hid) given the parameters, theta.\n",
    "    \"\"\"\n",
    "    k1, x, z = data\n",
    "    k2, pi, T, E = theta\n",
    "    assert k1 == k2\n",
    "    \n",
    "    # FIXME: compute the likelihood\n",
    "    p = pi[z[0]]\n",
    "    for i, s in enumerate(z[1:]):\n",
    "        p *= T[z[i], s]\n",
    "    for i, _ in enumerate(z):\n",
    "        p *= E[z[i], x[i]]\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some rudementary tests that it works; maybe you should test more?\n",
    "assert_almost_equal(lik(hmm_data(3, 'A', 'N'), theta), 0.5)\n",
    "assert_almost_equal(lik(hmm_data(3, 'AC', 'NC'), theta), 0.01)\n",
    "assert_almost_equal(lik(hmm_data(3, 'ACGTTCGA', 'NCCCNRRR'), theta), 7.86432e-09)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As should be obvious here, the likelihood gets very small very quickly. This is expected, since we are multiplying numbers in the range 0 to 1 together, and there isn't anything we can do about. It is also a problem, however, since floating point numbers have a finite resolution and eventually we will see all the likelihoods as indistinguishable from zero.\n",
    "\n",
    "Because of this, we usually do not compute the likelihood of large data, but rather the *log*-likelihood.\n",
    "\n",
    "The logarithm will also run into problems eventually--there is no good way of dealing with floating point numbers--but it doesn't happen as quickly, and if we compute the log-likelihood we can easily deal with genomic sized data (especially when the genomes in question are bacterial).\n",
    "\n",
    "Implement a function that computes the logarithm of the likelihood instead. You shouldn't just take the log of the function above--that would defeat the purpose as we would get zero for long sequences, and taking the log of that is not valid--but you can use the log of the input parameters and replace multipliation with addition, and then you should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_each(x: ArrayLike) -> ArrayLike:\n",
    "    \"\"\"\n",
    "    Take the log of each component.\n",
    "    \n",
    "    This is just numpy.log, but disabling warnings if x contains zero.\n",
    "    \"\"\"\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return np.log(x)\n",
    "\n",
    "def log_lik(data: HMMData, theta: HMMParam) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood of the data (obs,hid) given the parameters, theta.\n",
    "    \"\"\"\n",
    "    k1, x, z = data\n",
    "    k2, pi, T, E = theta\n",
    "    assert k1 == k2\n",
    "\n",
    "    pi, T, E = log_each(pi), log_each(T), log_each(E)\n",
    "\n",
    "    # FIXME: compute the likelihood\n",
    "    p = pi[z[0]]\n",
    "    for i, s in enumerate(z[1:]):\n",
    "        p += T[z[i], s]\n",
    "    for i, _ in enumerate(z):\n",
    "        p += E[z[i], x[i]]\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some rudementary tests that it works; maybe you should test more?\n",
    "assert_almost_equal(log_lik(hmm_data(3, 'A', 'N'), theta), np.log(0.5))\n",
    "assert_almost_equal(log_lik(hmm_data(3, 'AC', 'NC'), theta), np.log(0.01))\n",
    "assert_almost_equal(log_lik(hmm_data(3, 'ACGTTCGA', 'NCCCNRRR'), theta), np.log(7.86432e-09))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can compute the log-likelihood of short sequences, we should also be able to compute them for our full genomes--it just might take a little longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(log_lik(data1_3, theta), -3055335.10505437)\n",
    "assert_almost_equal(log_lik(data2_3, theta), -float(\"inf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-likelihood for the second genome is -inf, which means that the likelihood is zero (in this context). That is probably because the data contains a transition that has probability zero in the parameters, and that is likely an indication that the parameters we pulled our of a hat weren't that good after all. We should probably estimate the parameters instead of guessing them.\n",
    "\n",
    "## Estimating parameters\n",
    "\n",
    "When we have both the observed and the hidden sequence, estimating paramters is easy. We simply count how often we see the various events, and then we normalise to get probabilities. If you want to get technical, we are doing a maximum likelihood estimation on multinomial distributions, but why get technical?\n",
    "\n",
    "We will estimate from our data sets independently, so we don't need to count to figure out that `pi` should give one state probability one and all others probability zero; the first observed hidden state is the only state we observe the model starting in. (In general, we would estimate from many data sets, but we don't care here; in any case, both sequences start in `N`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pi(data: HMMData) -> ArrayLike:\n",
    "    \"\"\"Estimate the starting probability from the two sequences in an HMM with K hidden states.\"\"\"\n",
    "    k, _, z = data\n",
    "    pi = np.zeros(k)\n",
    "    pi[z[0]] = 1.0\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating pi for 3-state HMM\n",
    "pi_3 = estimate_pi(data1_3)\n",
    "assert_almost_equal(pi_3, [0, 1, 0])\n",
    "# Estimating pi for 7-state HMM\n",
    "pi_7 = estimate_pi(data1_7)\n",
    "assert_almost_equal(pi_7, [0, 0, 0, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the emission probabilities you need to count how often we see `(hid[i],obs[i])` and for transition probabilities how often you see `(obs[i-1],obs[i])`. The functions below should count these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_emissions(data: HMMData) -> ArrayLike:\n",
    "    \"\"\"Count how often we see the different emissions in the data.\"\"\"\n",
    "    k, obs, hid = data\n",
    "    counts = np.zeros((k, 4))  # How often each of the k states emit A,C,G,T.\n",
    "    # FIXME: count the emissions\n",
    "    for x, z in zip(obs, hid):\n",
    "        counts[z, x] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(\n",
    "    count_emissions(data1_3),\n",
    "    np.array([[227971., 133045., 152692., 214779.],\n",
    "              [161166.,  90377.,  94437., 159197.],\n",
    "              [183196., 129927., 112961., 192693.]])\n",
    ")\n",
    "assert_almost_equal(\n",
    "    count_emissions(data2_3),\n",
    "    np.array([[275056., 135918., 164202., 252896.],\n",
    "              [166547.,  83826.,  86048., 166486.],\n",
    "              [271660., 174583., 143318., 290945.]])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_transitions(data: HMMData) -> ArrayLike:\n",
    "    \"\"\"Count how often we see the different transitions in the data.\"\"\"\n",
    "    k, _, z = data\n",
    "    counts = np.zeros((k, k))  # How often each of the k*k state transitions\n",
    "    # FIXME: count the transitions\n",
    "    for i in range(len(z) - 1):\n",
    "        counts[z[i], z[i+1]] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_trans(data: HMMData) -> ArrayLike:\n",
    "    \"\"\"Estimate the transition matrix from the data.\"\"\"\n",
    "    counts = count_transitions(data)\n",
    "    for i, row in enumerate(counts):\n",
    "        counts[i] /= sum(row)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Using doc-test to test the functions in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    hidden_states('NNCCCCCCNNRRRRRRN')\n",
      "Expecting:\n",
      "    [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1]\n",
      "ok\n",
      "Trying:\n",
      "    hidden_states7('NNCCCCCCNNRRRRRRN')\n",
      "Expecting:\n",
      "    [3, 3, 0, 1, 2, 0, 1, 2, 3, 3, 4, 5, 6, 4, 5, 6, 3]\n",
      "ok\n",
      "Trying:\n",
      "    observed_states('ACAGTTC')\n",
      "Expecting:\n",
      "    [0, 1, 0, 2, 3, 3, 1]\n",
      "ok\n",
      "Trying:\n",
      "    rev_hidden_states([1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1])\n",
      "Expecting:\n",
      "    'NNCCCCCCNNRRRRRRN'\n",
      "ok\n",
      "Trying:\n",
      "    rev_hidden_states7([3, 3, 0, 1, 2, 0, 1, 2, 3, 3, 4, 5, 6, 4, 5, 6, 3])\n",
      "Expecting:\n",
      "    'NNCCCCCCNNRRRRRRN'\n",
      "ok\n",
      "Trying:\n",
      "    rev_observed_states([0, 1, 0, 2, 3, 3, 1])\n",
      "Expecting:\n",
      "    'ACAGTTC'\n",
      "ok\n",
      "9 items had no tests:\n",
      "    __main__\n",
      "    __main__.HMMParam\n",
      "    __main__._VSCODE_getVariableInfo\n",
      "    __main__._VSCODE_getVariableProperties\n",
      "    __main__._VSCODE_getVariableTypes\n",
      "    __main__.hmm_params\n",
      "    __main__.lik\n",
      "    __main__.log_each\n",
      "    __main__.log_lik\n",
      "6 items passed all tests:\n",
      "   1 tests in __main__.hidden_states\n",
      "   1 tests in __main__.hidden_states7\n",
      "   1 tests in __main__.observed_states\n",
      "   1 tests in __main__.rev_hidden_states\n",
      "   1 tests in __main__.rev_hidden_states7\n",
      "   1 tests in __main__.rev_observed_states\n",
      "6 tests in 15 items.\n",
      "6 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010000000000000002"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.testmod(verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
